# IJCAI 2024 Tutorial: Visually-Rich Document Understanding and Intelligence: Recent Advances and Benchmarks
Visually Rich Documents (VRDs), including scanned images and PDF files, have become ubiquitous for recording and preserving information. There are approximately 2.5 trillion such documents worldwide. The information and knowledge in documents such as academic papers , financial forms and industry annual reports are usually qualified by experts. 
Managing and extracting information from VRDs is crucial for emerging AI applications like dialogue systems and recommendation engines. VRDs contain high-quality multimodal content, often expert-verified, making them valuable for training large pretrained models, particularly in specialized fields like AI teaching and data analysis. To tackle this, diverse deep learning-based document understanding frameworks have been proposed. These frameworks cover various tasks such as document layout analysis (LA), structure parsing (SP), visual question answering (VQA), and key information extraction (KIE), enabling precise extraction of unstructured data from VRDs. This tutorial on document understanding and intelligence is highly relevant to the diverse audience of IJCAI, offering insights into emerging challenges and practical applications of document understanding and intelligence in AI research. 
<div style="text-align:center;">
  <img src="https://github.com/adlnlp/vrd_IU/assets/81132254/5bdf4401-f33f-4643-92ba-e48d6406afe6" alt="Larger Image" width="600"/>
</div>

# Tutorial Schedule
This tutorial will consist of a **3.5-hour (half-day)** hybrid lecture and laboratory-style representation that covers the topics of document understanding in great detail. The lecture session will cover the aforementioned topics, including document understanding downstream tasks with benchmark datasets and techniques adopted by SoTAs. The hands-on laboratories will introduce how to set up and implement deep learning models to address real-world problems.

1. **Introduction [15 mins]**
    - Motivation and Significance
    - Introduction to Document Understanding
    - Challenges of Document Understanding

2. **Document Understanding Downstream Tasks [40 mins]**
    - Document Structural Understanding
        - Layout Analysis
        - Structure Parsing
    - Document Content Understanding
        - Key Information Extraction
        - Visual Question Answering

3. **Document Understanding Techniques [40 mins]**
    - Feature Engineering
    - Cross-modality Fusion
    - Encoder Architecture
    - Pretraining Techniques

4. **Demo: VRD Understanding with LLMs in Bank System (Bank of Korea Team) [30 mins]**

5. **Laboratories in Real-world Applications**
    - Academic Paper Layout Understanding [30 mins]
    - Complex Form Key Information Extraction [30 mins]

6. **Summary and Future Trends**
# Tutorial Presentors

<div style="display: flex; justify-content: center; flex-wrap: wrap;">
    <img src="/figures/caren_ceremony.jpeg" alt="Dr. Soyeon Caren Han" width="100" style="object-fit: contain; margin: 10px;">
    <img src="/figures/yihao.jpeg" alt="Mr. Yihao Ding" width="100" style="object-fit: contain; margin: 10px;">
    <img src="/figures/josiah.jpg" alt="Dr. Josiah Poon" width="100" style="object-fit: contain; margin: 10px;">
    <img src="/figures/seong-bae-park.jpeg" alt="Prof. Seong-Bae Park" width="100" style="object-fit: contain; margin: 10px;">
    <img src="/figures/Mitra-Prasenjit.jpeg" alt="Prof. Prasenjit Mitra" width="100" style="object-fit: contain; margin: 10px;">
</div>


- **Dr. Soyeon Caren Han** is a co-leader of AD-NLP (Australia Deep Learning NLP Group), a Senior lecturer (Associate Professor in U.S. System) at the University of Melbourne, and an honorary senior lecturer (honorary Associate Professor in U.S. System) at the University of Sydney and the University of Edinburgh. After her Ph.D. (in 2017), she worked for six years at the University of Sydney. Her research interests include Natural Language Processing with Deep Learning. She is broadly interested in several research topics, including visual-linguistic multimodal learning, abusive language detection, document analysis, and recommender systems. More information can be found at [her website](https://drcarenhan.github.io/).

- **Mr. Yihao Ding** is a PhD candidate at the School of Computer Science, University of Sydney and a visiting scholar at the School of Computer Science, University of Melbourne. He is a Research Assistant at the School of Earth Science, University of Western Australia, working on applying trustable LLMs in geoscience. He received his Bachelor's Degree and Master's Degree in 2015 and 2018 in Geospatial Engineering and another Master's Degree in Information Technology in 2020. His research interests include deep learning-based document analysis, information retrieval, and question-answering. He has published several papers in top-tier conferences and journals, e.g. CVPR, ACL, IJCAI, SIGIR, AAAI, ECML-PKDD, CIKM, COLING, and Frontiers.

- **Dr. Josiah Poon** is a co-leader of AD-NLP (Australia Deep Learning NLP Group) and a Senior Lecturer at the School of Computer Science, University of Sydney. Heâ€™s been using traditional machine learning techniques, paying particular attention to learning from imbalanced datasets, short-string text classification, and data complexity analysis. He has coordinated a multidisciplinary team consisting of computer scientists, pharmacists, western medicine & traditional Chinese medicine researchers and practitioners since 2007. He co-leads a joint big-data laboratory for integrative medicine (Acclaim) established between the University of Sydney and the Chinese University of Hong Kong to study medical/health problems using computational tools.

- **Prof. Seong-Bae Park** is a prominent professor at Kyung Hee University's Department of Computer Engineering, and a leading authority in machine learning, natural language processing, and text mining. Armed with a Ph.D. in Computer Science and Engineering from Seoul National University, Dr. Park boasts an illustrious research career marked by pioneering contributions and patented innovations across various domains, such as automatic word spacing, ontology-based search, and personalized content retrieval. Beyond his scholarly endeavors, Dr. Park's extensive involvement in conference organization further underscores his profound impact on the academic community. He has held critical roles in prestigious conferences, including chairing the Communications and Liaison Committee of AFNLP and serving as Program Chair for renowned events like PRICAI. His tenure at Kyung Hee University and past appointments at Kyungpook National University exemplify his unwavering dedication to advancing research and computer science education, solidifying his status as a stalwart in the field.

- **Prof. Prasenjit Mitra** is a Professor at Pennsylvania State University and a visiting Professor at Leibniz University. Hannover's L3S Research Center in Germany boasts an illustrious academic career since obtaining his PhD in Electrical Engineering from Stanford University in 2003. With research interests spanning artificial intelligence, machine learning, and natural language processing, Mitra has garnered support from notable entities, including the NSF, DoE, DoD, and corporations like Microsoft and Lockheed Martin. His scholarly contributions exceed 200 peer-reviewed papers, reflecting his significant impact on the field as evidenced by an h-index of 60 and over 14,660 citations. Recognized for his excellence with awards such as the IEEE VIS Test of Time and Best Paper at ISCRAM, Mitra has also shaped future scholars by supervising up to 20 PhD dissertations and leading several key workshops.
# Citation

If you find this tutorial useful in your research, please cite it as follows:

```bibtex
@misc{ijcai2024_vrd_tutorial,
  author       = {Soyeon Caren Han, Yihao Ding, Josiah Poon, Seong-Bae Park and Prasenjit Mitra},
  title        = {Visually-Rich Document Understanding and Intelligence: Recent Advances and Benchmarks},
  conference   = {The 33rd International Joint Conference on Artificial Intelligence},
  year         = 2024,
  url          = {https://github.com/your-repo/ijcai2024-vrd-tutorial},
  note         = {GitHub repository}
}

